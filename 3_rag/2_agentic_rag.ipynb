{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8324170a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fc1d6e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78c65f55",
   "metadata": {},
   "source": [
    "### Run this if you are using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc61a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-openai langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82281e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import userdata\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
    "# os.environ[\"LANGSMITH_PROJECT\"] = \"ncit-workshop\"\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"QDRANT_API_KEY\"] = userdata.get(\"QDRANT_API_KEY\")\n",
    "# os.environ[\"QDRANT_URL\"] = \"qdrant-host\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0117420",
   "metadata": {},
   "source": [
    "### Run this if you are running VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259425ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from core import load_vault_env\n",
    "\n",
    "load_vault_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407c568",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a52a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "from typing import Annotated, Literal, TypedDict, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from qdrant_client.models import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6bc71f",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf25a0",
   "metadata": {},
   "source": [
    "#### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a599e",
   "metadata": {},
   "source": [
    "#### Initialize clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    collection_name=\"ncit-workshop-simple-rag\",\n",
    "    embedding=embeddings,\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7f4cb",
   "metadata": {},
   "source": [
    "### Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining tool using LangChain's tool decorator\n",
    "@tool\n",
    "def retrieve_relevant_docs(\n",
    "    question: str,\n",
    "    filter: Literal[\n",
    "        \"finance\",\n",
    "        \"it_policy\",\n",
    "        \"hr_policy\",\n",
    "        \"legal_policy\",\n",
    "        \"operations_policy\",\n",
    "        \"engineering_policy\",\n",
    "    ]\n",
    "    | None = None,\n",
    "    k: int = 3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents from the vector store based on the question and optional filter.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n[CHAIN LOG] Searching for: '{question} in '{filter or 'ALL'}'\")\n",
    "\n",
    "    q_filter = None\n",
    "    if filter:\n",
    "        q_filter = models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"metadata.category\", match=models.MatchValue(value=filter)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Perform search with scores\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        query=question, k=k, filter=q_filter\n",
    "    )\n",
    "\n",
    "    # Filter by Threshold & Format\n",
    "    valid_context = []\n",
    "    for doc, score in results:\n",
    "        if score >= 0.5:\n",
    "            valid_context.append(\n",
    "                f\"Policy ID: {doc.metadata['policy_id']}\\n\"\n",
    "                f\"Topic: {doc.metadata['topic']}\\n\"\n",
    "                f\"Rule: {doc.page_content}\"\n",
    "            )\n",
    "\n",
    "    if not valid_context:\n",
    "        return \"NO RELEVANT DOCUMENT FOUND.\"\n",
    "\n",
    "    return \"\\n\\n\".join(valid_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e03e3b",
   "metadata": {},
   "source": [
    "### RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent = create_agent(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    tools=[retrieve_relevant_docs],\n",
    "    system_prompt=SystemMessage(\n",
    "        content=[\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": (\n",
    "                    \"You are a strictly factual HR Policy Bot.\"\n",
    "                    \"Answer the question based ONLY on the context provided below.\"\n",
    "                    \"Cite the Policy ID and topic for every fact you state.\"\n",
    "                ),\n",
    "            }\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a25c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also provider the filter parameter to narrow down the search\n",
    "question = \"What is the hotel spending limit for major metro areas like NYC? (filter: 'finance')\"\n",
    "for step in rag_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62dfe27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "797b9030",
   "metadata": {},
   "source": [
    "## SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c1686",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///data.db\")\n",
    "\n",
    "print(f\"Dialect: {db.dialect}\")\n",
    "print(f\"Available Tables: {db.get_usable_table_names()}\")\n",
    "print(f\"Sample output: {db.run('SELECT * from trips')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee44ed",
   "metadata": {},
   "source": [
    "#### Initialize LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9db9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(name=\"gpt-4.1-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da7384e",
   "metadata": {},
   "source": [
    "#### SqlDatabaseToolkit available tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b88c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "for toolkit_tool in tools:\n",
    "    print(f\"{toolkit_tool.name}: {toolkit_tool.description}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8281b4",
   "metadata": {},
   "source": [
    "### Create Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc9387",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run,\n",
    "then look at the results of the query and return the answer. Unless the user\n",
    "specifies a specific number of example they wish to obtain, always limit your\n",
    "query to at most {top_k} results.\n",
    "\n",
    "You can order the results by a relevent column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the columns that are relevant to the question.\n",
    "\n",
    "You MUST double check your query before executing it. If you get an error while\n",
    "executing a query, try to fix the query and execute it again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the databsae to see what you\n",
    "can query, Do NOT skip this step.\n",
    "\n",
    "Then you should query the schema for the most relevant tables.\n",
    "\"\"\".format(\n",
    "    dialect=db.dialect,\n",
    "    top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c8f58d",
   "metadata": {},
   "source": [
    "#### Langchain Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1636ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67157199",
   "metadata": {},
   "source": [
    "#### Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fef0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which trip had the most expense?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
