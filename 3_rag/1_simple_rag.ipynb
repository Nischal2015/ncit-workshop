{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25b0b1c7",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Nischal2015/ncit-workshop/blob/main/3_rag/1_simple_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ee347",
   "metadata": {},
   "source": [
    "## Lab 1\n",
    "### Building a \"Traditional\" Rag System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d169c",
   "metadata": {},
   "source": [
    "### Run this if you are using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a60fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-openai langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1530d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import userdata\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
    "# os.environ[\"LANGSMITH_PROJECT\"] = \"ncit-workshop\"\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"QDRANT_API_KEY\"] = userdata.get(\"QDRANT_API_KEY\")\n",
    "# os.environ[\"QDRANT_URL\"] = \"qdrant-host\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5edad3",
   "metadata": {},
   "source": [
    "### Run this if you are running VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a63f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from core import load_vault_env\n",
    "\n",
    "load_vault_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c15fb0",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c7198",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe161f1",
   "metadata": {},
   "source": [
    "#### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a710e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e4d78",
   "metadata": {},
   "source": [
    "#### Initialize clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3855a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0.2)\n",
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    collection_name=\"ncit-workshop-simple-rag\",\n",
    "    embedding=embeddings,\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa939cc",
   "metadata": {},
   "source": [
    "### The Actual RAG (Retrieval Augmented Generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15293723",
   "metadata": {},
   "source": [
    "#### Retriever Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5697c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import models\n",
    "\n",
    "\n",
    "def retrieve_relevant_docs(query: dict[str, str], k: int = 3):\n",
    "    question = query[\"question\"]\n",
    "    category = query.get(\"filter\", None)\n",
    "\n",
    "    print(f\"\\n[CHAIN LOG] Searching for: '{query} in '{category or 'ALL'}'\")\n",
    "\n",
    "    q_filter = None\n",
    "    if category:\n",
    "        q_filter = models.Filter(\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"metadata.category\", match=models.MatchValue(value=category)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Perform search with scores\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        query=question, k=k, filter=q_filter\n",
    "    )\n",
    "\n",
    "    # Filter by Threshold & Format\n",
    "    valid_context = []\n",
    "    for doc, score in results:\n",
    "        if score >= 0.5:\n",
    "            valid_context.append(\n",
    "                f\"Policy ID: {doc.metadata['policy_id']}\\n\"\n",
    "                f\"Topic: {doc.metadata['topic']}\\n\"\n",
    "                f\"Rule: {doc.page_content}\"\n",
    "            )\n",
    "\n",
    "    if not valid_context:\n",
    "        return \"NO RELEVANT DOCUMENT FOUND.\"\n",
    "\n",
    "    return \"\\n\\n\".join(valid_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9ef29",
   "metadata": {},
   "source": [
    "#### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fe7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a strictly factual HR Policy Bot.\n",
    "Answer the question based ONLY on the context provided below. \n",
    "Cite the Policy ID and topic for every fact you state.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea0703",
   "metadata": {},
   "source": [
    "#### Build the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d32787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use RunnableParallel to pass the question through, while calculating context\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": RunnableLambda(retrieve_relevant_docs),\n",
    "            \"question\": lambda x: x[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c53f8",
   "metadata": {},
   "source": [
    "### Execution Scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c330935",
   "metadata": {},
   "source": [
    "##### Scenario 1: Searching with a filter (The \"Happy Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266586f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We explicitly tell it to look in 'finance' because the user is asking about money.\n",
    "response = rag_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What is the hotel spending limit for major metro areas like NYC?\",\n",
    "        \"filter\": \"finance\",\n",
    "    }\n",
    ")\n",
    "print(f\"\\nðŸ¤– [AI REPLY]:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf912dec",
   "metadata": {},
   "source": [
    "##### Scenario 2: Searching with a filter but asking an irrelevant question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows why filtering is safer. It won't accidentally find IT password rules\n",
    "# just because they contain the word \"secure\" or \"access\".\n",
    "response = rag_chain.invoke(\n",
    "    {\"question\": \"How many characters long must passwords be?\", \"filter\": \"finance\"}\n",
    ")\n",
    "print(f\"\\nðŸ¤– [AI REPLY]:\\n{response}\")\n",
    "# Expect: No results or low scores because we forced it to look in Finance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a1f45f",
   "metadata": {},
   "source": [
    "##### Scenario 3: General Search (No filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke({\"question\": \"What is the policy on VPN access?\"})\n",
    "print(f\"\\nðŸ¤– [AI REPLY]:\\n{response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
