{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3c7026",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Nischal2015/ncit-workshop/blob/main/2_deep_research/1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f47cd5",
   "metadata": {},
   "source": [
    "## Lab 1\n",
    "### Building a \"Deep Research\" Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d1956",
   "metadata": {},
   "source": [
    "### Run this if you are using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfa688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langgraph langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import userdata\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
    "# os.environ[\"LANGSMITH_PROJECT\"] = \"ncit-workshop\"\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8134d2ef",
   "metadata": {},
   "source": [
    "### Run this if you are running VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "from core import load_vault_env\n",
    "\n",
    "load_vault_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288acbe6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, Literal\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5f8d9",
   "metadata": {},
   "source": [
    "### Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66bcc7",
   "metadata": {},
   "source": [
    "### Definining Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b15ee8",
   "metadata": {},
   "source": [
    "##### Researcher Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Child State\n",
    "class ResearchState(TypedDict):\n",
    "    query: str\n",
    "    findings: Annotated[list, operator.add]\n",
    "    loop_count: int\n",
    "\n",
    "\n",
    "# Structured Output\n",
    "class Evaluation(BaseModel):\n",
    "    status: Literal[\"sufficient\", \"insufficient\"] = Field(\n",
    "        description=\"Is the info good enough?\"\n",
    "    )\n",
    "    new_query: str = Field(\"Refined query if insufficient\")\n",
    "\n",
    "\n",
    "def search_step(state: ResearchState) -> Command[Literal[\"evaluate_step\"]]:\n",
    "    print(f\"  [Child] Searching: {state['query']} (Iter: {state['loop_count']})\")\n",
    "    try:\n",
    "        result = tavily.search(state[\"query\"], max_results=2, search_depth=\"basic\")\n",
    "        content = \"\\n\".join([r[\"content\"] for r in result.get(\"results\", [])])\n",
    "        finding = f\"--- Search Iteration {state['loop_count']} ---\\n{content}\\n\"\n",
    "    except Exception as e:\n",
    "        finding = f\"Error: {e}\"\n",
    "\n",
    "    # Return update and move to evaluation\n",
    "    return Command(\n",
    "        update={\"findings\": [finding], \"loop_count\": state[\"loop_count\"] + 1},\n",
    "        goto=\"evaluate_step\",\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_step(state: ResearchState) -> Command[Literal[\"search_step\", \"__end__\"]]:\n",
    "    print(\"  [Child] Evaluating findings...\")\n",
    "\n",
    "    context = \"\\n\".join(state[\"findings\"])\n",
    "    evaluator = llm.with_structured_output(Evaluation)\n",
    "\n",
    "    res = evaluator.invoke(f\"Query: {state['query']}\\n\\nFindings:\\n{context}\")\n",
    "\n",
    "    if res.status == \"sufficient\" or state[\"loop_count\"] >= 3:\n",
    "        return Command(goto=\"__end__\")\n",
    "    else:\n",
    "        return Command(update={\"query\": res.new_query}, goto=\"search_step\")\n",
    "\n",
    "\n",
    "# --- BUILD CHILD GRAPH ---\n",
    "research_builder = StateGraph(ResearchState)\n",
    "research_builder.add_node(\"search_step\", search_step)\n",
    "research_builder.add_node(\"evaluate_step\", evaluate_step)\n",
    "research_builder.add_edge(START, \"search_step\")\n",
    "\n",
    "research_graph = research_builder.compile()\n",
    "research_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3494121",
   "metadata": {},
   "source": [
    "##### Editor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35603da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PARENT STATE ---\n",
    "class EditorState(TypedDict):\n",
    "    topic: str\n",
    "    subtopics: list[str]\n",
    "    final_report: str\n",
    "    research_results: Annotated[dict, lambda a, b: {**a, **b}]\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    subtopics: list[str] = Field(\n",
    "        description=\"List of 3 distinct sub-questions to research.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def planner_node(state: EditorState) -> Command[Literal[\"research_orchestrator\"]]:\n",
    "    print(f\"\\n[Parent] Planning research for: {state['topic']}\")\n",
    "\n",
    "    planner = llm.with_structured_output(Plan)\n",
    "    res = planner.invoke(f\"Topic: {state['topic']}\")\n",
    "\n",
    "    return Command(update={\"subtopics\": res.subtopics}, goto=\"research_orchestrator\")\n",
    "\n",
    "\n",
    "def research_orchestrator(state: EditorState) -> Command[Literal[\"writer_node\"]]:\n",
    "    print(\"[Parent] Delegating to Researcher Agent...\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for topic in state[\"subtopics\"]:\n",
    "        print(f\"\\n--- Spawning Child Agent for: {topic} ---\")\n",
    "\n",
    "        # Invoke child research graph\n",
    "        child_result = research_graph.invoke(\n",
    "            {\"query\": topic, \"findings\": [], \"loop_count\": 0}\n",
    "        )\n",
    "\n",
    "        full_text = \"\\n\".join(child_result[\"findings\"])\n",
    "        results[topic] = full_text\n",
    "\n",
    "    return Command(update={\"research_results\": results}, goto=\"writer_node\")\n",
    "\n",
    "\n",
    "def writer_node(state: EditorState) -> Command[Literal[\"__end__\"]]:\n",
    "    print(\"\\n[Parent] Synthesizing Final Report...\")\n",
    "\n",
    "    context = \"\"\n",
    "    for topic, data in state[\"research_results\"].items():\n",
    "        context += f\"## {topic}\\n{data}\\n\\n\"\n",
    "\n",
    "    prompt = f\"Write a comprehensive report on '{state['topic']}' using the following data:\\n\\n{context}\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    return Command(update={\"final_report\": response.content}, goto=\"__end__\")\n",
    "\n",
    "\n",
    "# --- BUILD PARENT GRAPH ---\n",
    "parent_builder = StateGraph(EditorState)\n",
    "parent_builder.add_node(\"planner_node\", planner_node)\n",
    "parent_builder.add_node(\"research_orchestrator\", research_orchestrator)\n",
    "parent_builder.add_node(\"writer_node\", writer_node)\n",
    "\n",
    "parent_builder.add_edge(START, \"planner_node\")\n",
    "\n",
    "# Compile with Checkpointer (Memory)\n",
    "checkpointer = InMemorySaver()\n",
    "app = parent_builder.compile(checkpointer=checkpointer)\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36238dd4",
   "metadata": {},
   "source": [
    "### Invoke the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_config = {\"configurable\": {\"thread_id\": \"workshop_v3_latest\"}}\n",
    "\n",
    "topic = \"Comparison of M4 Apple Silicon vs NVIDIA Blackwell for AI Inference\"\n",
    "\n",
    "print(f\"Starting Multi-Agent Deep Research on: {topic}\")\n",
    "\n",
    "# Run\n",
    "final_state = app.invoke({\"topic\": topic}, config=thread_config)\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 50)\n",
    "print(\"FINAL DEEP RESEARCH REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(final_state[\"final_report\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
